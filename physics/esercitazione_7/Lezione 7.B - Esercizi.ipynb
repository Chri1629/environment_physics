{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='start'></a>\n",
    "# Reti neurali con Tensor Flow\n",
    "\n",
    "In questo notebook vengono presentati degli esercizi sulle reti neurali con Tensor Flow.\n",
    "\n",
    "Provate a svolgere il seguente esercizio:<br>\n",
    "1) [pp -> H -> ZZ -> 4lepton](#section1)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## pp -> H -> ZZ -> 4lepton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creare una rete neurale per analizzare i dati prodotti dagli studi di pp -> H -> ZZ -> 4lepton nel contesto delle ricerche mono-Higgs da parte della collaborazione CMS. I programmi usano le ntuple ridotte (con il nome dell'albero radice HZZ4LeptonsAnalysisReduced) create con Root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "treename = 'HZZ4LeptonsAnalysisReduced'\n",
    "filename ='ntuple_4mu_bkg.root'\n",
    "\n",
    "upfile = uproot.open(filename)\n",
    "params = upfile[treename].arrays() # dictionary of NumPy arrays\n",
    "\n",
    "VARS = [b'f_massjj']\n",
    "df = pd.DataFrame(params, columns=VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iterable of expressions must be strings or name, Interpretation pairs (length-2 tuples), not b'f_mass4l'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8920f0a1c879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mVARS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mb'f_mass4l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb'f_massjj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mupfile_VV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ntuple_4mu_VV.root'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mparams_VV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupfile_VV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtreename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVARS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mupfile_BKG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ntuple_4mu_bkg.root'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mparams_BKG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupfile_BKG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtreename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVARS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinelearning/lib/python3.7/site-packages/uproot/behaviors/TBranch.py\u001b[0m in \u001b[0;36marrays\u001b[0;34m(self, expressions, cut, filter_name, filter_typename, filter_branch, aliases, language, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library, how)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0maliases\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0mget_from_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m         )\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/machinelearning/lib/python3.7/site-packages/uproot/behaviors/TBranch.py\u001b[0m in \u001b[0;36m_regularize_expressions\u001b[0;34m(hasbranches, expressions, cut, filter_name, filter_typename, filter_branch, keys, aliases, language, get_from_cache)\u001b[0m\n\u001b[1;32m   3277\u001b[0m                         \u001b[0;34m\"iterable of expressions must be strings or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m                         \u001b[0;34m\"name, Interpretation pairs (length-2 tuples), not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m                         \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3280\u001b[0m                     )\n\u001b[1;32m   3281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: iterable of expressions must be strings or name, Interpretation pairs (length-2 tuples), not b'f_mass4l'"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "treename = 'HZZ4LeptonsAnalysisReduced'\n",
    "\n",
    "VARS = [b'f_mass4l', b'f_massjj']\n",
    "upfile_VV = uproot.open('ntuple_4mu_VV.root')\n",
    "params_VV = upfile_VV[treename].arrays(VARS)\n",
    "upfile_BKG = uproot.open('ntuple_4mu_bkg.root')\n",
    "params_BKG = upfile_BKG[treename].arrays(VARS)\n",
    "\n",
    "df_VV = pd.DataFrame(params_VV, columns=VARS)\n",
    "df_BKG = pd.DataFrame(params_BKG, columns=VARS)\n",
    "\n",
    "# convert the feature names to utf-8 to simplify management\n",
    "for v in VARS:\n",
    "    df_VV = df_VV.rename(columns={v: v.decode('utf-8')})\n",
    "    df_BKG = df_BKG.rename(columns={v: v.decode('utf-8')})\n",
    "VARS = [v.decode('utf-8') for v in VARS]\n",
    "    \n",
    "# cut out undefined variables VARS[0] and VARS[1] > -999\n",
    "df_VV = df_VV[(df_VV[VARS[0]] > -999) & (df_VV[VARS[1]] > -999)]\n",
    "df_BKG = df_BKG[(df_BKG[VARS[0]] > -999) & (df_BKG[VARS[1]] > -999)] \n",
    "\n",
    "# add isSignal variable\n",
    "df_VV['isSignal'] = np.ones(len(df_VV)) \n",
    "df_BKG['isSignal'] = np.zeros(len(df_BKG))\n",
    "\n",
    "df_all = pd.concat([df_VV, df_BKG])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo una rete densa, con un singolo livello nascosto completamente connesso con lo stesso numero di neuroni delle variabili di input.\n",
    "\n",
    "Possiamo quindi usare la funzione di attivazione `sigmoide` per produrre un'uscita di probabilit√† nell'intervallo da 0 a 1.\n",
    "\n",
    "Infine usiamo la funzione di loss `binary_crossentropy` durante l'allenamento, una funzione di perdita standard per problemi di classificazione binaria.\n",
    "\n",
    "Infine utimmizziamo il modello con l'algoritmo Adam per il grandient descend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Clicca qui per tornare all'inizio della pagina](#start)<a id='start'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
